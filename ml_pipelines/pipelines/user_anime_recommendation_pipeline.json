{
  "pipelineSpec": {
    "components": {
      "comp-component": {
        "executorLabel": "exec-component",
        "inputDefinitions": {
          "artifacts": {
            "anime_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "test_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "train_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "user_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "val_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "data_format": {
              "type": "STRING"
            },
            "early_stop_num_epochs": {
              "type": "INT"
            },
            "learning_rate": {
              "type": "DOUBLE"
            },
            "max_num_epochs": {
              "type": "INT"
            },
            "optimizer": {
              "type": "STRING"
            },
            "user_anime_embedding_size": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-10": {
        "executorLabel": "exec-component-10",
        "inputDefinitions": {
          "artifacts": {
            "input_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "data_format": {
              "type": "STRING"
            },
            "model_type": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-2": {
        "executorLabel": "exec-component-2",
        "inputDefinitions": {
          "artifacts": {
            "input_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "data_format": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-3": {
        "executorLabel": "exec-component-3",
        "inputDefinitions": {
          "artifacts": {
            "anime_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "test_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "train_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "user_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "val_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "anime_embedding_size": {
              "type": "INT"
            },
            "data_format": {
              "type": "STRING"
            },
            "early_stop_num_epochs": {
              "type": "INT"
            },
            "learning_rate": {
              "type": "DOUBLE"
            },
            "max_num_epochs": {
              "type": "INT"
            },
            "model_type": {
              "type": "STRING"
            },
            "optimizer": {
              "type": "STRING"
            },
            "scoring_layer_size": {
              "type": "INT"
            },
            "user_embedding_size": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-4": {
        "executorLabel": "exec-component-4",
        "inputDefinitions": {
          "artifacts": {
            "input_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "data_format": {
              "type": "STRING"
            },
            "model_type": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-5": {
        "executorLabel": "exec-component-5",
        "inputDefinitions": {
          "artifacts": {
            "anime_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "test_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "train_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "user_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "val_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "anime_embedding_size": {
              "type": "INT"
            },
            "data_format": {
              "type": "STRING"
            },
            "early_stop_num_epochs": {
              "type": "INT"
            },
            "learning_rate": {
              "type": "DOUBLE"
            },
            "max_num_epochs": {
              "type": "INT"
            },
            "model_type": {
              "type": "STRING"
            },
            "optimizer": {
              "type": "STRING"
            },
            "scoring_layer_size": {
              "type": "INT"
            },
            "user_embedding_size": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-6": {
        "executorLabel": "exec-component-6",
        "inputDefinitions": {
          "artifacts": {
            "input_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "data_format": {
              "type": "STRING"
            },
            "model_type": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-7": {
        "executorLabel": "exec-component-7",
        "inputDefinitions": {
          "artifacts": {
            "anime_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "test_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "train_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "user_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "val_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "anime_embedding_size": {
              "type": "INT"
            },
            "data_format": {
              "type": "STRING"
            },
            "early_stop_num_epochs": {
              "type": "INT"
            },
            "learning_rate": {
              "type": "DOUBLE"
            },
            "max_num_epochs": {
              "type": "INT"
            },
            "model_type": {
              "type": "STRING"
            },
            "optimizer": {
              "type": "STRING"
            },
            "scoring_layer_size": {
              "type": "INT"
            },
            "user_embedding_size": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-8": {
        "executorLabel": "exec-component-8",
        "inputDefinitions": {
          "artifacts": {
            "input_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "data_format": {
              "type": "STRING"
            },
            "model_type": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-component-9": {
        "executorLabel": "exec-component-9",
        "inputDefinitions": {
          "artifacts": {
            "anime_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "test_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "train_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "user_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "val_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "anime_embedding_size": {
              "type": "INT"
            },
            "data_format": {
              "type": "STRING"
            },
            "early_stop_num_epochs": {
              "type": "INT"
            },
            "learning_rate": {
              "type": "DOUBLE"
            },
            "max_num_epochs": {
              "type": "INT"
            },
            "model_type": {
              "type": "STRING"
            },
            "optimizer": {
              "type": "STRING"
            },
            "scoring_layer_size": {
              "type": "INT"
            },
            "user_embedding_size": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "model_path": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-condition-list-ranking-2": {
        "dag": {
          "outputs": {
            "artifacts": {
              "component-3-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "metrics_path",
                    "producerSubtask": "component-3"
                  }
                ]
              },
              "get-model-training-details-2-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "output_metrics",
                    "producerSubtask": "get-model-training-details-2"
                  }
                ]
              }
            }
          },
          "tasks": {
            "component-3": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-3"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-7",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-8",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-9"
              ],
              "inputs": {
                "artifacts": {
                  "anime_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  },
                  "test_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-9"
                    }
                  },
                  "train_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-7"
                    }
                  },
                  "user_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "val_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-8"
                    }
                  }
                },
                "parameters": {
                  "anime_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "early_stop_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "1"
                      }
                    }
                  },
                  "learning_rate": {
                    "runtimeValue": {
                      "constantValue": {
                        "doubleValue": 0.005
                      }
                    }
                  },
                  "max_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "5"
                      }
                    }
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "list_ranking"
                      }
                    }
                  },
                  "optimizer": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "adam"
                      }
                    }
                  },
                  "scoring_layer_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "user_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "256"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime list ranking"
              }
            },
            "component-4": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-4"
              },
              "dependentTasks": [
                "component-3"
              ],
              "inputs": {
                "artifacts": {
                  "input_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-6-output_data_path"
                  },
                  "model_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-3"
                    }
                  }
                },
                "parameters": {
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "list_ranking"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime list ranking"
              }
            },
            "gcs-to-bq-table-and-vertexai-2": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-gcs-to-bq-table-and-vertexai-2"
              },
              "dependentTasks": [
                "component-4"
              ],
              "inputs": {
                "artifacts": {
                  "gcs_input_data": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "component-4"
                    }
                  }
                },
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_infer"
                      }
                    }
                  },
                  "gcs_input_data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "gcs_input_data_schema": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "[[\"user_id\", \"STRING\"], [\"anime_id\", \"STRING\"], [\"score\", \"FLOAT\"]]"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime list ranking to BQ"
              }
            },
            "get-model-training-details-2": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-get-model-training-details-2"
              },
              "dependentTasks": [
                "component-3"
              ],
              "inputs": {
                "artifacts": {
                  "input_metrics": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "metrics_path",
                      "producerTask": "component-3"
                    }
                  },
                  "input_model": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-3"
                    }
                  }
                },
                "parameters": {
                  "labels": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "{\"anime_embedding_size\": 128, \"user_embedding_size\": 128, \"scoring_layer_size\": 128, \"learning_rate\": 0.005, \"optimizer\": \"adam\", \"max_num_epochs\": 5, \"early_stop_num_epochs\": 1}"
                      }
                    }
                  },
                  "model_name": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_model"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime list ranking display"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-7": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-7"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_train"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    ),\n    train_data AS (\n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n    ),\n    train_data_random_order AS (\n        SELECT user_id, \n               anime_id, \n               CAST(score AS STRING) AS score, \n               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY RAND()) - 1 AS random_order_anime_per_user\n        FROM train_data\n    ),\n    train_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM train_data_random_order\n        GROUP BY user_id, DIV(random_order_anime_per_user, 10)\n        HAVING ARRAY_LENGTH(anime_id) = 10\n    ),\n    val_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n    ),\n    val_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM val_data \n        GROUP BY user_id\n    ),\n    test_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n    ),\n    test_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM test_data \n        GROUP BY user_id\n    )\n    \n        SELECT user_id, ARRAY_TO_STRING(anime_id, '|') AS anime_id, ARRAY_TO_STRING(score, '|') AS score\n        FROM train_data_list\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: train user anime list ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-8": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-8"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_val"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    ),\n    train_data AS (\n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n    ),\n    train_data_random_order AS (\n        SELECT user_id, \n               anime_id, \n               CAST(score AS STRING) AS score, \n               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY RAND()) - 1 AS random_order_anime_per_user\n        FROM train_data\n    ),\n    train_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM train_data_random_order\n        GROUP BY user_id, DIV(random_order_anime_per_user, 10)\n        HAVING ARRAY_LENGTH(anime_id) = 10\n    ),\n    val_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n    ),\n    val_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM val_data \n        GROUP BY user_id\n    ),\n    test_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n    ),\n    test_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM test_data \n        GROUP BY user_id\n    )\n    \n        SELECT user_id, ARRAY_TO_STRING(anime_id, '|') AS anime_id, ARRAY_TO_STRING(score, '|') AS score\n        FROM val_data_list\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: validation user anime list ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-9": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-9"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_test"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    ),\n    train_data AS (\n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n    ),\n    train_data_random_order AS (\n        SELECT user_id, \n               anime_id, \n               CAST(score AS STRING) AS score, \n               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY RAND()) - 1 AS random_order_anime_per_user\n        FROM train_data\n    ),\n    train_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM train_data_random_order\n        GROUP BY user_id, DIV(random_order_anime_per_user, 10)\n        HAVING ARRAY_LENGTH(anime_id) = 10\n    ),\n    val_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n    ),\n    val_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM val_data \n        GROUP BY user_id\n    ),\n    test_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n    ),\n    test_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM test_data \n        GROUP BY user_id\n    )\n    \n        SELECT user_id, ARRAY_TO_STRING(anime_id, '|') AS anime_id, ARRAY_TO_STRING(score, '|') AS score\n        FROM test_data_list\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: test user anime list ranking"
              }
            }
          }
        },
        "inputDefinitions": {
          "artifacts": {
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-6-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "pipelineparam--data_format": {
              "type": "STRING"
            },
            "pipelineparam--dataset_id": {
              "type": "STRING"
            },
            "pipelineparam--list_ranking": {
              "type": "STRING"
            },
            "pipelineparam--project_id": {
              "type": "STRING"
            },
            "pipelineparam--run_retrieval": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "component-3-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-2-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-condition-list-ranking-5": {
        "dag": {
          "outputs": {
            "artifacts": {
              "component-7-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "metrics_path",
                    "producerSubtask": "component-7"
                  }
                ]
              },
              "get-model-training-details-4-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "output_metrics",
                    "producerSubtask": "get-model-training-details-4"
                  }
                ]
              }
            }
          },
          "tasks": {
            "component-7": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-7"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-15",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-16",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-17"
              ],
              "inputs": {
                "artifacts": {
                  "anime_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  },
                  "test_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-17"
                    }
                  },
                  "train_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-15"
                    }
                  },
                  "user_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "val_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-16"
                    }
                  }
                },
                "parameters": {
                  "anime_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "early_stop_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "1"
                      }
                    }
                  },
                  "learning_rate": {
                    "runtimeValue": {
                      "constantValue": {
                        "doubleValue": 0.005
                      }
                    }
                  },
                  "max_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "5"
                      }
                    }
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "list_ranking"
                      }
                    }
                  },
                  "optimizer": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "adam"
                      }
                    }
                  },
                  "scoring_layer_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "user_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "256"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime list ranking"
              }
            },
            "component-8": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-8"
              },
              "dependentTasks": [
                "component-7"
              ],
              "inputs": {
                "artifacts": {
                  "input_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-14-output_data_path"
                  },
                  "model_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-7"
                    }
                  }
                },
                "parameters": {
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "list_ranking"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime list ranking"
              }
            },
            "gcs-to-bq-table-and-vertexai-4": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-gcs-to-bq-table-and-vertexai-4"
              },
              "dependentTasks": [
                "component-8"
              ],
              "inputs": {
                "artifacts": {
                  "gcs_input_data": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "component-8"
                    }
                  }
                },
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_infer"
                      }
                    }
                  },
                  "gcs_input_data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "gcs_input_data_schema": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "[[\"user_id\", \"STRING\"], [\"anime_id\", \"STRING\"], [\"score\", \"FLOAT\"]]"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime list ranking to BQ"
              }
            },
            "get-model-training-details-4": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-get-model-training-details-4"
              },
              "dependentTasks": [
                "component-7"
              ],
              "inputs": {
                "artifacts": {
                  "input_metrics": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "metrics_path",
                      "producerTask": "component-7"
                    }
                  },
                  "input_model": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-7"
                    }
                  }
                },
                "parameters": {
                  "labels": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "{\"anime_embedding_size\": 128, \"user_embedding_size\": 128, \"scoring_layer_size\": 128, \"learning_rate\": 0.005, \"optimizer\": \"adam\", \"max_num_epochs\": 5, \"early_stop_num_epochs\": 1}"
                      }
                    }
                  },
                  "model_name": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_model"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime list ranking display"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-15": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-15"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_train"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    ),\n    train_data AS (\n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n    ),\n    train_data_random_order AS (\n        SELECT user_id, \n               anime_id, \n               CAST(score AS STRING) AS score, \n               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY RAND()) - 1 AS random_order_anime_per_user\n        FROM train_data\n    ),\n    train_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM train_data_random_order\n        GROUP BY user_id, DIV(random_order_anime_per_user, 10)\n        HAVING ARRAY_LENGTH(anime_id) = 10\n    ),\n    val_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n    ),\n    val_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM val_data \n        GROUP BY user_id\n    ),\n    test_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n    ),\n    test_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM test_data \n        GROUP BY user_id\n    )\n    \n        SELECT user_id, ARRAY_TO_STRING(anime_id, '|') AS anime_id, ARRAY_TO_STRING(score, '|') AS score\n        FROM train_data_list\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: train user anime list ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-16": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-16"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_val"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    ),\n    train_data AS (\n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n    ),\n    train_data_random_order AS (\n        SELECT user_id, \n               anime_id, \n               CAST(score AS STRING) AS score, \n               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY RAND()) - 1 AS random_order_anime_per_user\n        FROM train_data\n    ),\n    train_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM train_data_random_order\n        GROUP BY user_id, DIV(random_order_anime_per_user, 10)\n        HAVING ARRAY_LENGTH(anime_id) = 10\n    ),\n    val_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n    ),\n    val_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM val_data \n        GROUP BY user_id\n    ),\n    test_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n    ),\n    test_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM test_data \n        GROUP BY user_id\n    )\n    \n        SELECT user_id, ARRAY_TO_STRING(anime_id, '|') AS anime_id, ARRAY_TO_STRING(score, '|') AS score\n        FROM val_data_list\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: validation user anime list ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-17": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-17"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_list_ranking_test"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    ),\n    train_data AS (\n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n    ),\n    train_data_random_order AS (\n        SELECT user_id, \n               anime_id, \n               CAST(score AS STRING) AS score, \n               ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY RAND()) - 1 AS random_order_anime_per_user\n        FROM train_data\n    ),\n    train_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM train_data_random_order\n        GROUP BY user_id, DIV(random_order_anime_per_user, 10)\n        HAVING ARRAY_LENGTH(anime_id) = 10\n    ),\n    val_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n    ),\n    val_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM val_data \n        GROUP BY user_id\n    ),\n    test_data AS (\n        SELECT user_id, anime_id, CAST(score AS STRING) AS score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n    ),\n    test_data_list AS (\n        SELECT user_id, \n               ARRAY_AGG(anime_id) AS anime_id, \n               ARRAY_AGG(score) AS score \n        FROM test_data \n        GROUP BY user_id\n    )\n    \n        SELECT user_id, ARRAY_TO_STRING(anime_id, '|') AS anime_id, ARRAY_TO_STRING(score, '|') AS score\n        FROM test_data_list\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: test user anime list ranking"
              }
            }
          }
        },
        "inputDefinitions": {
          "artifacts": {
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-14-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "pipelineparam--data_format": {
              "type": "STRING"
            },
            "pipelineparam--dataset_id": {
              "type": "STRING"
            },
            "pipelineparam--list_ranking": {
              "type": "STRING"
            },
            "pipelineparam--project_id": {
              "type": "STRING"
            },
            "pipelineparam--run_retrieval": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "component-7-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-4-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-condition-no-run-retrieval-4": {
        "dag": {
          "outputs": {
            "artifacts": {
              "component-7-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "component-7-metrics_path",
                    "producerSubtask": "condition-list-ranking-5"
                  }
                ]
              },
              "component-9-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "component-9-metrics_path",
                    "producerSubtask": "condition-ranking-6"
                  }
                ]
              },
              "get-model-training-details-4-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "get-model-training-details-4-output_metrics",
                    "producerSubtask": "condition-list-ranking-5"
                  }
                ]
              },
              "get-model-training-details-5-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "get-model-training-details-5-output_metrics",
                    "producerSubtask": "condition-ranking-6"
                  }
                ]
              }
            }
          },
          "tasks": {
            "condition-list-ranking-5": {
              "componentRef": {
                "name": "comp-condition-list-ranking-5"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-14"
              ],
              "inputs": {
                "artifacts": {
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-14-output_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-14"
                    }
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  }
                },
                "parameters": {
                  "pipelineparam--data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "pipelineparam--dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "pipelineparam--list_ranking": {
                    "componentInputParameter": "pipelineparam--list_ranking"
                  },
                  "pipelineparam--project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "pipelineparam--run_retrieval": {
                    "componentInputParameter": "pipelineparam--run_retrieval"
                  }
                }
              },
              "taskInfo": {
                "name": "condition-list-ranking-5"
              },
              "triggerPolicy": {
                "condition": "inputs.parameters['pipelineparam--list_ranking'].string_value == 'true'"
              }
            },
            "condition-ranking-6": {
              "componentRef": {
                "name": "comp-condition-ranking-6"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-14"
              ],
              "inputs": {
                "artifacts": {
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-14-output_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-14"
                    }
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  }
                },
                "parameters": {
                  "pipelineparam--data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "pipelineparam--dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "pipelineparam--list_ranking": {
                    "componentInputParameter": "pipelineparam--list_ranking"
                  },
                  "pipelineparam--project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "pipelineparam--run_retrieval": {
                    "componentInputParameter": "pipelineparam--run_retrieval"
                  }
                }
              },
              "taskInfo": {
                "name": "condition-ranking-6"
              },
              "triggerPolicy": {
                "condition": "inputs.parameters['pipelineparam--list_ranking'].string_value == 'false'"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-13": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-13"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_cross_anime"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n        WITH \n        list_anime AS (\n            \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n        ),\n        filtered_user_anime_on_anime AS (\n            \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n        ),\n        list_users AS (\n            \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n        )\n        SELECT A.user_id, B.anime_id\n        FROM list_users A\n        CROSS JOIN list_anime B  \n    "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: user cross anime"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-14": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-14"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-13"
              ],
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_cross_anime_to_rank"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "pipelineparam--dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "pipelineparam--project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n        WITH \n        list_anime AS (\n            \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n        ),\n        filtered_user_anime_on_anime AS (\n            \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n        ),\n        list_users AS (\n            \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n        ),\n        filtered_user_anime AS (\n            \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n        )\n        SELECT A.user_id, A.anime_id\n        FROM `{{$.inputs.parameters['pipelineparam--project_id']}}.{{$.inputs.parameters['pipelineparam--dataset_id']}}.user_cross_anime` A\n        LEFT JOIN filtered_user_anime B\n        ON A.user_id = B.user_id AND A.anime_id = B.anime_id\n        WHERE B.status IS NULL\n    "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: user cross anime to be ranked"
              }
            }
          }
        },
        "inputDefinitions": {
          "artifacts": {
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "pipelineparam--data_format": {
              "type": "STRING"
            },
            "pipelineparam--dataset_id": {
              "type": "STRING"
            },
            "pipelineparam--list_ranking": {
              "type": "STRING"
            },
            "pipelineparam--project_id": {
              "type": "STRING"
            },
            "pipelineparam--run_retrieval": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "component-7-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "component-9-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-4-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-5-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-condition-ranking-3": {
        "dag": {
          "outputs": {
            "artifacts": {
              "component-5-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "metrics_path",
                    "producerSubtask": "component-5"
                  }
                ]
              },
              "get-model-training-details-3-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "output_metrics",
                    "producerSubtask": "get-model-training-details-3"
                  }
                ]
              }
            }
          },
          "tasks": {
            "component-5": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-5"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-10",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-11",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-12"
              ],
              "inputs": {
                "artifacts": {
                  "anime_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  },
                  "test_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-12"
                    }
                  },
                  "train_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-10"
                    }
                  },
                  "user_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "val_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-11"
                    }
                  }
                },
                "parameters": {
                  "anime_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "early_stop_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "1"
                      }
                    }
                  },
                  "learning_rate": {
                    "runtimeValue": {
                      "constantValue": {
                        "doubleValue": 0.005
                      }
                    }
                  },
                  "max_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "5"
                      }
                    }
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "ranking"
                      }
                    }
                  },
                  "optimizer": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "adam"
                      }
                    }
                  },
                  "scoring_layer_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "user_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "256"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime ranking"
              }
            },
            "component-6": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-6"
              },
              "dependentTasks": [
                "component-5"
              ],
              "inputs": {
                "artifacts": {
                  "input_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-6-output_data_path"
                  },
                  "model_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-5"
                    }
                  }
                },
                "parameters": {
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "ranking"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime ranking"
              }
            },
            "gcs-to-bq-table-and-vertexai-3": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-gcs-to-bq-table-and-vertexai-3"
              },
              "dependentTasks": [
                "component-6"
              ],
              "inputs": {
                "artifacts": {
                  "gcs_input_data": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "component-6"
                    }
                  }
                },
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_infer"
                      }
                    }
                  },
                  "gcs_input_data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "gcs_input_data_schema": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "[[\"user_id\", \"STRING\"], [\"anime_id\", \"STRING\"], [\"score\", \"FLOAT\"]]"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime ranking to BQ"
              }
            },
            "get-model-training-details-3": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-get-model-training-details-3"
              },
              "dependentTasks": [
                "component-5"
              ],
              "inputs": {
                "artifacts": {
                  "input_metrics": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "metrics_path",
                      "producerTask": "component-5"
                    }
                  },
                  "input_model": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-5"
                    }
                  }
                },
                "parameters": {
                  "labels": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "{\"anime_embedding_size\": 128, \"user_embedding_size\": 128, \"scoring_layer_size\": 128, \"learning_rate\": 0.005, \"optimizer\": \"adam\", \"max_num_epochs\": 5, \"early_stop_num_epochs\": 1}"
                      }
                    }
                  },
                  "model_name": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_model"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime ranking display"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-10": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-10"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_train"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    )\n    \n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: train user anime ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-11": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-11"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_val"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    )\n    \n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: validation user anime ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-12": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-12"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_test"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    )\n    \n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: test user anime ranking"
              }
            }
          }
        },
        "inputDefinitions": {
          "artifacts": {
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-6-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "pipelineparam--data_format": {
              "type": "STRING"
            },
            "pipelineparam--dataset_id": {
              "type": "STRING"
            },
            "pipelineparam--list_ranking": {
              "type": "STRING"
            },
            "pipelineparam--project_id": {
              "type": "STRING"
            },
            "pipelineparam--run_retrieval": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "component-5-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-3-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-condition-ranking-6": {
        "dag": {
          "outputs": {
            "artifacts": {
              "component-9-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "metrics_path",
                    "producerSubtask": "component-9"
                  }
                ]
              },
              "get-model-training-details-5-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "output_metrics",
                    "producerSubtask": "get-model-training-details-5"
                  }
                ]
              }
            }
          },
          "tasks": {
            "component-10": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-10"
              },
              "dependentTasks": [
                "component-9"
              ],
              "inputs": {
                "artifacts": {
                  "input_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-14-output_data_path"
                  },
                  "model_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-9"
                    }
                  }
                },
                "parameters": {
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "ranking"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime ranking"
              }
            },
            "component-9": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-9"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-18",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-19",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-20"
              ],
              "inputs": {
                "artifacts": {
                  "anime_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  },
                  "test_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-20"
                    }
                  },
                  "train_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-18"
                    }
                  },
                  "user_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "val_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-19"
                    }
                  }
                },
                "parameters": {
                  "anime_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "early_stop_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "1"
                      }
                    }
                  },
                  "learning_rate": {
                    "runtimeValue": {
                      "constantValue": {
                        "doubleValue": 0.005
                      }
                    }
                  },
                  "max_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "5"
                      }
                    }
                  },
                  "model_type": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "ranking"
                      }
                    }
                  },
                  "optimizer": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "adam"
                      }
                    }
                  },
                  "scoring_layer_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  },
                  "user_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "256"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime ranking"
              }
            },
            "gcs-to-bq-table-and-vertexai-5": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-gcs-to-bq-table-and-vertexai-5"
              },
              "dependentTasks": [
                "component-10"
              ],
              "inputs": {
                "artifacts": {
                  "gcs_input_data": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "component-10"
                    }
                  }
                },
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_infer"
                      }
                    }
                  },
                  "gcs_input_data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "gcs_input_data_schema": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "[[\"user_id\", \"STRING\"], [\"anime_id\", \"STRING\"], [\"score\", \"FLOAT\"]]"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime ranking to BQ"
              }
            },
            "get-model-training-details-5": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-get-model-training-details-5"
              },
              "dependentTasks": [
                "component-9"
              ],
              "inputs": {
                "artifacts": {
                  "input_metrics": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "metrics_path",
                      "producerTask": "component-9"
                    }
                  },
                  "input_model": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component-9"
                    }
                  }
                },
                "parameters": {
                  "labels": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "{\"anime_embedding_size\": 128, \"user_embedding_size\": 128, \"scoring_layer_size\": 128, \"learning_rate\": 0.005, \"optimizer\": \"adam\", \"max_num_epochs\": 5, \"early_stop_num_epochs\": 1}"
                      }
                    }
                  },
                  "model_name": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_model"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime ranking display"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-18": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-18"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_train"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    )\n    \n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order >= 21\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: train user anime ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-19": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-19"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_val"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    )\n    \n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 11 AND 20\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: validation user anime ranking"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-20": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-20"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_ranking_test"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n    \n    )\n    \n        SELECT user_id, anime_id, score\n        FROM filtered_ordered_user_anime\n        WHERE user_anime_order BETWEEN 1 AND 10\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: test user anime ranking"
              }
            }
          }
        },
        "inputDefinitions": {
          "artifacts": {
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-14-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "pipelineparam--data_format": {
              "type": "STRING"
            },
            "pipelineparam--dataset_id": {
              "type": "STRING"
            },
            "pipelineparam--list_ranking": {
              "type": "STRING"
            },
            "pipelineparam--project_id": {
              "type": "STRING"
            },
            "pipelineparam--run_retrieval": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "component-9-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-5-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-condition-yes-run-retrieval-1": {
        "dag": {
          "outputs": {
            "artifacts": {
              "component-3-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "component-3-metrics_path",
                    "producerSubtask": "condition-list-ranking-2"
                  }
                ]
              },
              "component-5-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "component-5-metrics_path",
                    "producerSubtask": "condition-ranking-3"
                  }
                ]
              },
              "component-metrics_path": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "metrics_path",
                    "producerSubtask": "component"
                  }
                ]
              },
              "get-model-training-details-2-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "get-model-training-details-2-output_metrics",
                    "producerSubtask": "condition-list-ranking-2"
                  }
                ]
              },
              "get-model-training-details-3-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "get-model-training-details-3-output_metrics",
                    "producerSubtask": "condition-ranking-3"
                  }
                ]
              },
              "get-model-training-details-output_metrics": {
                "artifactSelectors": [
                  {
                    "outputArtifactKey": "output_metrics",
                    "producerSubtask": "get-model-training-details"
                  }
                ]
              }
            }
          },
          "tasks": {
            "component": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-3",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-4",
                "run-query-save-to-bq-table-and-gcs-and-vertexai-5"
              ],
              "inputs": {
                "artifacts": {
                  "anime_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  },
                  "test_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-5"
                    }
                  },
                  "train_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-3"
                    }
                  },
                  "user_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "val_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-4"
                    }
                  }
                },
                "parameters": {
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "early_stop_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "1"
                      }
                    }
                  },
                  "learning_rate": {
                    "runtimeValue": {
                      "constantValue": {
                        "doubleValue": 0.005
                      }
                    }
                  },
                  "max_num_epochs": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "5"
                      }
                    }
                  },
                  "optimizer": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "adam"
                      }
                    }
                  },
                  "user_anime_embedding_size": {
                    "runtimeValue": {
                      "constantValue": {
                        "intValue": "128"
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime retrieval"
              }
            },
            "component-2": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-component-2"
              },
              "dependentTasks": [
                "component"
              ],
              "inputs": {
                "artifacts": {
                  "input_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "model_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component"
                    }
                  }
                },
                "parameters": {
                  "data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime retrieval"
              }
            },
            "condition-list-ranking-2": {
              "componentRef": {
                "name": "comp-condition-list-ranking-2"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-6"
              ],
              "inputs": {
                "artifacts": {
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-6-output_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-6"
                    }
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  }
                },
                "parameters": {
                  "pipelineparam--data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "pipelineparam--dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "pipelineparam--list_ranking": {
                    "componentInputParameter": "pipelineparam--list_ranking"
                  },
                  "pipelineparam--project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "pipelineparam--run_retrieval": {
                    "componentInputParameter": "pipelineparam--run_retrieval"
                  }
                }
              },
              "taskInfo": {
                "name": "condition-list-ranking-2"
              },
              "triggerPolicy": {
                "condition": "inputs.parameters['pipelineparam--list_ranking'].string_value == 'true'"
              }
            },
            "condition-ranking-3": {
              "componentRef": {
                "name": "comp-condition-ranking-3"
              },
              "dependentTasks": [
                "run-query-save-to-bq-table-and-gcs-and-vertexai-6"
              ],
              "inputs": {
                "artifacts": {
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path"
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-6-output_data_path": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-6"
                    }
                  },
                  "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
                    "componentInputArtifact": "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path"
                  }
                },
                "parameters": {
                  "pipelineparam--data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "pipelineparam--dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "pipelineparam--list_ranking": {
                    "componentInputParameter": "pipelineparam--list_ranking"
                  },
                  "pipelineparam--project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "pipelineparam--run_retrieval": {
                    "componentInputParameter": "pipelineparam--run_retrieval"
                  }
                }
              },
              "taskInfo": {
                "name": "condition-ranking-3"
              },
              "triggerPolicy": {
                "condition": "inputs.parameters['pipelineparam--list_ranking'].string_value == 'false'"
              }
            },
            "gcs-to-bq-table-and-vertexai": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-gcs-to-bq-table-and-vertexai"
              },
              "dependentTasks": [
                "component-2"
              ],
              "inputs": {
                "artifacts": {
                  "gcs_input_data": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "output_data_path",
                      "producerTask": "component-2"
                    }
                  }
                },
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_retrieval_infer"
                      }
                    }
                  },
                  "gcs_input_data_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "gcs_input_data_schema": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "[[\"user_id\", \"STRING\"], [\"anime_id\", \"STRING\"]]"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime retrieval to BQ"
              }
            },
            "get-model-training-details": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-get-model-training-details"
              },
              "dependentTasks": [
                "component"
              ],
              "inputs": {
                "artifacts": {
                  "input_metrics": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "metrics_path",
                      "producerTask": "component"
                    }
                  },
                  "input_model": {
                    "taskOutputArtifact": {
                      "outputArtifactKey": "model_path",
                      "producerTask": "component"
                    }
                  }
                },
                "parameters": {
                  "labels": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "{\"user_anime_embedding_size\": 128, \"learning_rate\": 0.005, \"optimizer\": \"adam\", \"max_num_epochs\": 5, \"early_stop_num_epochs\": 1}"
                      }
                    }
                  },
                  "model_name": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_retrieval_model"
                      }
                    }
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  }
                }
              },
              "taskInfo": {
                "name": "TRAIN: user anime retrieval display"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-3": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-3"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_retrieval_train"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed'\n    \n    )\n    \n        SELECT user_id, anime_id \n        FROM filtered_ordered_user_anime \n        WHERE user_anime_order >= 21\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: train user anime retrieval"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-4": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-4"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_retrieval_val"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed'\n    \n    )\n    \n        SELECT user_id, anime_id \n        FROM filtered_ordered_user_anime \n        WHERE user_anime_order BETWEEN 11 AND 20\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: val user anime retrieval"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-5": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-5"
              },
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_retrieval_test"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n    WITH \n    list_anime AS (\n        \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n    ),\n    filtered_user_anime_on_anime AS (\n        \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n    ),\n    list_users AS (\n        \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n    ),\n    filtered_user_anime AS (\n        \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n    ),\n    filtered_ordered_user_anime AS (\n        \n        SELECT user_id, anime_id, score, ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY (last_interaction_date IS NOT NULL) DESC, last_interaction_date DESC) AS user_anime_order\n        FROM filtered_user_anime\n        WHERE status = 'completed'\n    \n    )\n    \n        SELECT user_id, anime_id \n        FROM filtered_ordered_user_anime \n        WHERE user_anime_order BETWEEN 1 AND 10\n        "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "DATA: test user anime retrieval"
              }
            },
            "run-query-save-to-bq-table-and-gcs-and-vertexai-6": {
              "cachingOptions": {
                "enableCache": true
              },
              "componentRef": {
                "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-6"
              },
              "dependentTasks": [
                "gcs-to-bq-table-and-vertexai"
              ],
              "inputs": {
                "parameters": {
                  "destination_dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "destination_table_id": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "user_anime_retrieval_to_rank"
                      }
                    }
                  },
                  "gcs_output_format": {
                    "componentInputParameter": "pipelineparam--data_format"
                  },
                  "pipelineparam--dataset_id": {
                    "componentInputParameter": "pipelineparam--dataset_id"
                  },
                  "pipelineparam--project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "project_id": {
                    "componentInputParameter": "pipelineparam--project_id"
                  },
                  "query": {
                    "runtimeValue": {
                      "constantValue": {
                        "stringValue": "\n        WITH \n        list_anime AS (\n            \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n        ),\n        filtered_user_anime_on_anime AS (\n            \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n        ),\n        list_users AS (\n            \n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    \n        ),\n        filtered_user_anime AS (\n            \n        SELECT A.*\n        FROM filtered_user_anime_on_anime A\n        INNER JOIN list_users B\n        ON A.user_id = B.user_id\n    \n        )\n        SELECT A.user_id, A.anime_id\n        FROM `{{$.inputs.parameters['pipelineparam--project_id']}}.{{$.inputs.parameters['pipelineparam--dataset_id']}}.user_anime_retrieval_infer` A\n        LEFT JOIN filtered_user_anime B\n        ON A.user_id = B.user_id AND A.anime_id = B.anime_id\n        WHERE B.status IS NULL\n    "
                      }
                    }
                  }
                }
              },
              "taskInfo": {
                "name": "INFER: user anime retrieval to be ranked"
              }
            }
          }
        },
        "inputDefinitions": {
          "artifacts": {
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            },
            "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "pipelineparam--data_format": {
              "type": "STRING"
            },
            "pipelineparam--dataset_id": {
              "type": "STRING"
            },
            "pipelineparam--list_ranking": {
              "type": "STRING"
            },
            "pipelineparam--project_id": {
              "type": "STRING"
            },
            "pipelineparam--run_retrieval": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "component-3-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "component-5-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "component-metrics_path": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-2-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-3-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "get-model-training-details-output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-gcs-to-bq-table-and-vertexai": {
        "executorLabel": "exec-gcs-to-bq-table-and-vertexai",
        "inputDefinitions": {
          "artifacts": {
            "gcs_input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_input_data_format": {
              "type": "STRING"
            },
            "gcs_input_data_schema": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-gcs-to-bq-table-and-vertexai-2": {
        "executorLabel": "exec-gcs-to-bq-table-and-vertexai-2",
        "inputDefinitions": {
          "artifacts": {
            "gcs_input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_input_data_format": {
              "type": "STRING"
            },
            "gcs_input_data_schema": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-gcs-to-bq-table-and-vertexai-3": {
        "executorLabel": "exec-gcs-to-bq-table-and-vertexai-3",
        "inputDefinitions": {
          "artifacts": {
            "gcs_input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_input_data_format": {
              "type": "STRING"
            },
            "gcs_input_data_schema": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-gcs-to-bq-table-and-vertexai-4": {
        "executorLabel": "exec-gcs-to-bq-table-and-vertexai-4",
        "inputDefinitions": {
          "artifacts": {
            "gcs_input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_input_data_format": {
              "type": "STRING"
            },
            "gcs_input_data_schema": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-gcs-to-bq-table-and-vertexai-5": {
        "executorLabel": "exec-gcs-to-bq-table-and-vertexai-5",
        "inputDefinitions": {
          "artifacts": {
            "gcs_input_data": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_input_data_format": {
              "type": "STRING"
            },
            "gcs_input_data_schema": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-get-model-training-details": {
        "executorLabel": "exec-get-model-training-details",
        "inputDefinitions": {
          "artifacts": {
            "input_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "input_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "labels": {
              "type": "STRING"
            },
            "model_name": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-get-model-training-details-2": {
        "executorLabel": "exec-get-model-training-details-2",
        "inputDefinitions": {
          "artifacts": {
            "input_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "input_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "labels": {
              "type": "STRING"
            },
            "model_name": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-get-model-training-details-3": {
        "executorLabel": "exec-get-model-training-details-3",
        "inputDefinitions": {
          "artifacts": {
            "input_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "input_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "labels": {
              "type": "STRING"
            },
            "model_name": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-get-model-training-details-4": {
        "executorLabel": "exec-get-model-training-details-4",
        "inputDefinitions": {
          "artifacts": {
            "input_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "input_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "labels": {
              "type": "STRING"
            },
            "model_name": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-get-model-training-details-5": {
        "executorLabel": "exec-get-model-training-details-5",
        "inputDefinitions": {
          "artifacts": {
            "input_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "input_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "labels": {
              "type": "STRING"
            },
            "model_name": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_metrics": {
              "artifactType": {
                "schemaTitle": "system.Metrics",
                "schemaVersion": "0.0.1"
              }
            },
            "output_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-10": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-10",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-11": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-11",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-12": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-12",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-13": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-13",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-14": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-14",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-15": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-15",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-16": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-16",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-17": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-17",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-18": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-18",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-19": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-19",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-2": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-2",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-20": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-20",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-3": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-3",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-4": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-4",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-5": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-5",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-6": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-6",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-7": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-7",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-8": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-8",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-9": {
        "executorLabel": "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-9",
        "inputDefinitions": {
          "parameters": {
            "destination_dataset_id": {
              "type": "STRING"
            },
            "destination_table_id": {
              "type": "STRING"
            },
            "gcs_output_format": {
              "type": "STRING"
            },
            "project_id": {
              "type": "STRING"
            },
            "query": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "output_data_path": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-component": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--train-data-path",
              "{{$.inputs.artifacts['train_data_path'].path}}",
              "--val-data-path",
              "{{$.inputs.artifacts['val_data_path'].path}}",
              "--test-data-path",
              "{{$.inputs.artifacts['test_data_path'].path}}",
              "--anime-data-path",
              "{{$.inputs.artifacts['anime_data_path'].path}}",
              "--user-data-path",
              "{{$.inputs.artifacts['user_data_path'].path}}",
              "--model-path",
              "{{$.outputs.artifacts['model_path'].path}}",
              "--metrics-path",
              "{{$.outputs.artifacts['metrics_path'].path}}",
              "--user-anime-embedding-size",
              "{{$.inputs.parameters['user_anime_embedding_size']}}",
              "--learning-rate",
              "{{$.inputs.parameters['learning_rate']}}",
              "--optimizer",
              "{{$.inputs.parameters['optimizer']}}",
              "--max-num-epochs",
              "{{$.inputs.parameters['max_num_epochs']}}",
              "--early-stop-num-epochs",
              "{{$.inputs.parameters['early_stop_num_epochs']}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_train_retrieval:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-10": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--model-path",
              "{{$.inputs.artifacts['model_path'].path}}",
              "--input-data-path",
              "{{$.inputs.artifacts['input_data_path'].path}}",
              "--output-data-path",
              "{{$.outputs.artifacts['output_data_path'].path}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_infer_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-2": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--model-path",
              "{{$.inputs.artifacts['model_path'].path}}",
              "--input-data-path",
              "{{$.inputs.artifacts['input_data_path'].path}}",
              "--output-data-path",
              "{{$.outputs.artifacts['output_data_path'].path}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_infer_retrieval:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-3": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--train-data-path",
              "{{$.inputs.artifacts['train_data_path'].path}}",
              "--val-data-path",
              "{{$.inputs.artifacts['val_data_path'].path}}",
              "--test-data-path",
              "{{$.inputs.artifacts['test_data_path'].path}}",
              "--anime-data-path",
              "{{$.inputs.artifacts['anime_data_path'].path}}",
              "--user-data-path",
              "{{$.inputs.artifacts['user_data_path'].path}}",
              "--model-path",
              "{{$.outputs.artifacts['model_path'].path}}",
              "--metrics-path",
              "{{$.outputs.artifacts['metrics_path'].path}}",
              "--anime-embedding-size",
              "{{$.inputs.parameters['anime_embedding_size']}}",
              "--user-embedding-size",
              "{{$.inputs.parameters['user_embedding_size']}}",
              "--scoring-layer-size",
              "{{$.inputs.parameters['scoring_layer_size']}}",
              "--learning-rate",
              "{{$.inputs.parameters['learning_rate']}}",
              "--optimizer",
              "{{$.inputs.parameters['optimizer']}}",
              "--max-num-epochs",
              "{{$.inputs.parameters['max_num_epochs']}}",
              "--early-stop-num-epochs",
              "{{$.inputs.parameters['early_stop_num_epochs']}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_train_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-4": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--model-path",
              "{{$.inputs.artifacts['model_path'].path}}",
              "--input-data-path",
              "{{$.inputs.artifacts['input_data_path'].path}}",
              "--output-data-path",
              "{{$.outputs.artifacts['output_data_path'].path}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_infer_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-5": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--train-data-path",
              "{{$.inputs.artifacts['train_data_path'].path}}",
              "--val-data-path",
              "{{$.inputs.artifacts['val_data_path'].path}}",
              "--test-data-path",
              "{{$.inputs.artifacts['test_data_path'].path}}",
              "--anime-data-path",
              "{{$.inputs.artifacts['anime_data_path'].path}}",
              "--user-data-path",
              "{{$.inputs.artifacts['user_data_path'].path}}",
              "--model-path",
              "{{$.outputs.artifacts['model_path'].path}}",
              "--metrics-path",
              "{{$.outputs.artifacts['metrics_path'].path}}",
              "--anime-embedding-size",
              "{{$.inputs.parameters['anime_embedding_size']}}",
              "--user-embedding-size",
              "{{$.inputs.parameters['user_embedding_size']}}",
              "--scoring-layer-size",
              "{{$.inputs.parameters['scoring_layer_size']}}",
              "--learning-rate",
              "{{$.inputs.parameters['learning_rate']}}",
              "--optimizer",
              "{{$.inputs.parameters['optimizer']}}",
              "--max-num-epochs",
              "{{$.inputs.parameters['max_num_epochs']}}",
              "--early-stop-num-epochs",
              "{{$.inputs.parameters['early_stop_num_epochs']}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_train_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-6": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--model-path",
              "{{$.inputs.artifacts['model_path'].path}}",
              "--input-data-path",
              "{{$.inputs.artifacts['input_data_path'].path}}",
              "--output-data-path",
              "{{$.outputs.artifacts['output_data_path'].path}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_infer_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-7": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--train-data-path",
              "{{$.inputs.artifacts['train_data_path'].path}}",
              "--val-data-path",
              "{{$.inputs.artifacts['val_data_path'].path}}",
              "--test-data-path",
              "{{$.inputs.artifacts['test_data_path'].path}}",
              "--anime-data-path",
              "{{$.inputs.artifacts['anime_data_path'].path}}",
              "--user-data-path",
              "{{$.inputs.artifacts['user_data_path'].path}}",
              "--model-path",
              "{{$.outputs.artifacts['model_path'].path}}",
              "--metrics-path",
              "{{$.outputs.artifacts['metrics_path'].path}}",
              "--anime-embedding-size",
              "{{$.inputs.parameters['anime_embedding_size']}}",
              "--user-embedding-size",
              "{{$.inputs.parameters['user_embedding_size']}}",
              "--scoring-layer-size",
              "{{$.inputs.parameters['scoring_layer_size']}}",
              "--learning-rate",
              "{{$.inputs.parameters['learning_rate']}}",
              "--optimizer",
              "{{$.inputs.parameters['optimizer']}}",
              "--max-num-epochs",
              "{{$.inputs.parameters['max_num_epochs']}}",
              "--early-stop-num-epochs",
              "{{$.inputs.parameters['early_stop_num_epochs']}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_train_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-8": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--model-path",
              "{{$.inputs.artifacts['model_path'].path}}",
              "--input-data-path",
              "{{$.inputs.artifacts['input_data_path'].path}}",
              "--output-data-path",
              "{{$.outputs.artifacts['output_data_path'].path}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_infer_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-component-9": {
          "container": {
            "command": [
              "python3",
              "task.py",
              "--model-type",
              "{{$.inputs.parameters['model_type']}}",
              "--data-format",
              "{{$.inputs.parameters['data_format']}}",
              "--train-data-path",
              "{{$.inputs.artifacts['train_data_path'].path}}",
              "--val-data-path",
              "{{$.inputs.artifacts['val_data_path'].path}}",
              "--test-data-path",
              "{{$.inputs.artifacts['test_data_path'].path}}",
              "--anime-data-path",
              "{{$.inputs.artifacts['anime_data_path'].path}}",
              "--user-data-path",
              "{{$.inputs.artifacts['user_data_path'].path}}",
              "--model-path",
              "{{$.outputs.artifacts['model_path'].path}}",
              "--metrics-path",
              "{{$.outputs.artifacts['metrics_path'].path}}",
              "--anime-embedding-size",
              "{{$.inputs.parameters['anime_embedding_size']}}",
              "--user-embedding-size",
              "{{$.inputs.parameters['user_embedding_size']}}",
              "--scoring-layer-size",
              "{{$.inputs.parameters['scoring_layer_size']}}",
              "--learning-rate",
              "{{$.inputs.parameters['learning_rate']}}",
              "--optimizer",
              "{{$.inputs.parameters['optimizer']}}",
              "--max-num-epochs",
              "{{$.inputs.parameters['max_num_epochs']}}",
              "--early-stop-num-epochs",
              "{{$.inputs.parameters['early_stop_num_epochs']}}"
            ],
            "image": "gcr.io/anime-rec-dev/user_anime_train_ranking:latest",
            "resources": {
              "cpuLimit": 16.0,
              "memoryLimit": 32.0
            }
          }
        },
        "exec-gcs-to-bq-table-and-vertexai": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "gcs_to_bq_table_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef gcs_to_bq_table_and_vertexai(\n    gcs_input_data:Input[Dataset],\n    gcs_input_data_format: str,\n    gcs_input_data_schema:list,\n    project_id:str, \n    destination_dataset_id: str, \n    destination_table_id: str\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    if gcs_input_data_format == 'csv':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            skip_leading_rows=1,\n            field_delimiter=',',\n            source_format=bigquery.SourceFormat.CSV\n        )\n    elif gcs_input_data_format == 'avro':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            source_format=bigquery.SourceFormat.AVRO,\n            use_avro_logical_types=True\n        )\n    else:\n        raise(f\"{gcs_input_data_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_input_data = gcs_input_data.path.replace('/gcs/', 'gs://') + \"/*\"\n\n    load_job = client.load_table_from_uri(\n        source_uris = gcs_input_data, \n        destination = table_ref, \n        job_config = job_config\n    )\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n    load_job.result()\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_input_data[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-gcs-to-bq-table-and-vertexai-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "gcs_to_bq_table_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef gcs_to_bq_table_and_vertexai(\n    gcs_input_data:Input[Dataset],\n    gcs_input_data_format: str,\n    gcs_input_data_schema:list,\n    project_id:str, \n    destination_dataset_id: str, \n    destination_table_id: str\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    if gcs_input_data_format == 'csv':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            skip_leading_rows=1,\n            field_delimiter=',',\n            source_format=bigquery.SourceFormat.CSV\n        )\n    elif gcs_input_data_format == 'avro':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            source_format=bigquery.SourceFormat.AVRO,\n            use_avro_logical_types=True\n        )\n    else:\n        raise(f\"{gcs_input_data_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_input_data = gcs_input_data.path.replace('/gcs/', 'gs://') + \"/*\"\n\n    load_job = client.load_table_from_uri(\n        source_uris = gcs_input_data, \n        destination = table_ref, \n        job_config = job_config\n    )\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n    load_job.result()\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_input_data[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-gcs-to-bq-table-and-vertexai-3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "gcs_to_bq_table_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef gcs_to_bq_table_and_vertexai(\n    gcs_input_data:Input[Dataset],\n    gcs_input_data_format: str,\n    gcs_input_data_schema:list,\n    project_id:str, \n    destination_dataset_id: str, \n    destination_table_id: str\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    if gcs_input_data_format == 'csv':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            skip_leading_rows=1,\n            field_delimiter=',',\n            source_format=bigquery.SourceFormat.CSV\n        )\n    elif gcs_input_data_format == 'avro':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            source_format=bigquery.SourceFormat.AVRO,\n            use_avro_logical_types=True\n        )\n    else:\n        raise(f\"{gcs_input_data_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_input_data = gcs_input_data.path.replace('/gcs/', 'gs://') + \"/*\"\n\n    load_job = client.load_table_from_uri(\n        source_uris = gcs_input_data, \n        destination = table_ref, \n        job_config = job_config\n    )\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n    load_job.result()\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_input_data[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-gcs-to-bq-table-and-vertexai-4": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "gcs_to_bq_table_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef gcs_to_bq_table_and_vertexai(\n    gcs_input_data:Input[Dataset],\n    gcs_input_data_format: str,\n    gcs_input_data_schema:list,\n    project_id:str, \n    destination_dataset_id: str, \n    destination_table_id: str\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    if gcs_input_data_format == 'csv':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            skip_leading_rows=1,\n            field_delimiter=',',\n            source_format=bigquery.SourceFormat.CSV\n        )\n    elif gcs_input_data_format == 'avro':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            source_format=bigquery.SourceFormat.AVRO,\n            use_avro_logical_types=True\n        )\n    else:\n        raise(f\"{gcs_input_data_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_input_data = gcs_input_data.path.replace('/gcs/', 'gs://') + \"/*\"\n\n    load_job = client.load_table_from_uri(\n        source_uris = gcs_input_data, \n        destination = table_ref, \n        job_config = job_config\n    )\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n    load_job.result()\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_input_data[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-gcs-to-bq-table-and-vertexai-5": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "gcs_to_bq_table_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef gcs_to_bq_table_and_vertexai(\n    gcs_input_data:Input[Dataset],\n    gcs_input_data_format: str,\n    gcs_input_data_schema:list,\n    project_id:str, \n    destination_dataset_id: str, \n    destination_table_id: str\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    if gcs_input_data_format == 'csv':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            skip_leading_rows=1,\n            field_delimiter=',',\n            source_format=bigquery.SourceFormat.CSV\n        )\n    elif gcs_input_data_format == 'avro':\n        job_config = bigquery.LoadJobConfig(\n            schema=[bigquery.SchemaField(x[0], x[1]) for x in gcs_input_data_schema],\n            source_format=bigquery.SourceFormat.AVRO,\n            use_avro_logical_types=True\n        )\n    else:\n        raise(f\"{gcs_input_data_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_input_data = gcs_input_data.path.replace('/gcs/', 'gs://') + \"/*\"\n\n    load_job = client.load_table_from_uri(\n        source_uris = gcs_input_data, \n        destination = table_ref, \n        job_config = job_config\n    )\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n    load_job.result()\n    logging.info(f\"Started exporting {gcs_input_data} to BQ table {table_ref.path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_input_data[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-get-model-training-details": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "get_model_training_details"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas==1.3.4' 'fsspec==2022.2.0' 'gcsfs==2022.2.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef get_model_training_details(\n    project_id:str,\n    input_model: Input[Model],\n    model_name:str,\n    labels:dict,\n    input_metrics: Input[Metrics],\n    output_model: Output[Model],\n    output_metrics: Output[Metrics]\n):  \n    import pandas as pd\n    from google.cloud import aiplatform\n\n    output_model.metadata[\"model_name\"] = model_name\n    for k, v in labels.items():\n        output_model.metadata[k] = v\n    output_model.path = f\"{input_model.path}/\"\n\n    metrics_df = pd.read_json(f\"{input_metrics.path}/metrics.json\")\n    for metric in metrics_df.iterrows():\n        metric_name = metric[1]['metrics']['name']\n        metric_value = metric[1]['metrics']['number_value']\n        output_metrics.log_metric(metric_name, metric_value)\n        output_model.metadata[metric_name] = metric_value\n\n    labels = {k: str(v).replace(\".\", \"\") for k, v in labels.items()}\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    aiplatform.Model.upload(\n        display_name = model_name,\n        artifact_uri = input_model.path,\n        serving_container_image_uri=\"gcr.io/anime-rec-dev/user_anime_infer_ranking:latest\",\n        labels = labels\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-get-model-training-details-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "get_model_training_details"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas==1.3.4' 'fsspec==2022.2.0' 'gcsfs==2022.2.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef get_model_training_details(\n    project_id:str,\n    input_model: Input[Model],\n    model_name:str,\n    labels:dict,\n    input_metrics: Input[Metrics],\n    output_model: Output[Model],\n    output_metrics: Output[Metrics]\n):  \n    import pandas as pd\n    from google.cloud import aiplatform\n\n    output_model.metadata[\"model_name\"] = model_name\n    for k, v in labels.items():\n        output_model.metadata[k] = v\n    output_model.path = f\"{input_model.path}/\"\n\n    metrics_df = pd.read_json(f\"{input_metrics.path}/metrics.json\")\n    for metric in metrics_df.iterrows():\n        metric_name = metric[1]['metrics']['name']\n        metric_value = metric[1]['metrics']['number_value']\n        output_metrics.log_metric(metric_name, metric_value)\n        output_model.metadata[metric_name] = metric_value\n\n    labels = {k: str(v).replace(\".\", \"\") for k, v in labels.items()}\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    aiplatform.Model.upload(\n        display_name = model_name,\n        artifact_uri = input_model.path,\n        serving_container_image_uri=\"gcr.io/anime-rec-dev/user_anime_infer_ranking:latest\",\n        labels = labels\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-get-model-training-details-3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "get_model_training_details"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas==1.3.4' 'fsspec==2022.2.0' 'gcsfs==2022.2.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef get_model_training_details(\n    project_id:str,\n    input_model: Input[Model],\n    model_name:str,\n    labels:dict,\n    input_metrics: Input[Metrics],\n    output_model: Output[Model],\n    output_metrics: Output[Metrics]\n):  \n    import pandas as pd\n    from google.cloud import aiplatform\n\n    output_model.metadata[\"model_name\"] = model_name\n    for k, v in labels.items():\n        output_model.metadata[k] = v\n    output_model.path = f\"{input_model.path}/\"\n\n    metrics_df = pd.read_json(f\"{input_metrics.path}/metrics.json\")\n    for metric in metrics_df.iterrows():\n        metric_name = metric[1]['metrics']['name']\n        metric_value = metric[1]['metrics']['number_value']\n        output_metrics.log_metric(metric_name, metric_value)\n        output_model.metadata[metric_name] = metric_value\n\n    labels = {k: str(v).replace(\".\", \"\") for k, v in labels.items()}\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    aiplatform.Model.upload(\n        display_name = model_name,\n        artifact_uri = input_model.path,\n        serving_container_image_uri=\"gcr.io/anime-rec-dev/user_anime_infer_ranking:latest\",\n        labels = labels\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-get-model-training-details-4": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "get_model_training_details"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas==1.3.4' 'fsspec==2022.2.0' 'gcsfs==2022.2.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef get_model_training_details(\n    project_id:str,\n    input_model: Input[Model],\n    model_name:str,\n    labels:dict,\n    input_metrics: Input[Metrics],\n    output_model: Output[Model],\n    output_metrics: Output[Metrics]\n):  \n    import pandas as pd\n    from google.cloud import aiplatform\n\n    output_model.metadata[\"model_name\"] = model_name\n    for k, v in labels.items():\n        output_model.metadata[k] = v\n    output_model.path = f\"{input_model.path}/\"\n\n    metrics_df = pd.read_json(f\"{input_metrics.path}/metrics.json\")\n    for metric in metrics_df.iterrows():\n        metric_name = metric[1]['metrics']['name']\n        metric_value = metric[1]['metrics']['number_value']\n        output_metrics.log_metric(metric_name, metric_value)\n        output_model.metadata[metric_name] = metric_value\n\n    labels = {k: str(v).replace(\".\", \"\") for k, v in labels.items()}\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    aiplatform.Model.upload(\n        display_name = model_name,\n        artifact_uri = input_model.path,\n        serving_container_image_uri=\"gcr.io/anime-rec-dev/user_anime_infer_ranking:latest\",\n        labels = labels\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-get-model-training-details-5": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "get_model_training_details"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas==1.3.4' 'fsspec==2022.2.0' 'gcsfs==2022.2.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef get_model_training_details(\n    project_id:str,\n    input_model: Input[Model],\n    model_name:str,\n    labels:dict,\n    input_metrics: Input[Metrics],\n    output_model: Output[Model],\n    output_metrics: Output[Metrics]\n):  \n    import pandas as pd\n    from google.cloud import aiplatform\n\n    output_model.metadata[\"model_name\"] = model_name\n    for k, v in labels.items():\n        output_model.metadata[k] = v\n    output_model.path = f\"{input_model.path}/\"\n\n    metrics_df = pd.read_json(f\"{input_metrics.path}/metrics.json\")\n    for metric in metrics_df.iterrows():\n        metric_name = metric[1]['metrics']['name']\n        metric_value = metric[1]['metrics']['number_value']\n        output_metrics.log_metric(metric_name, metric_value)\n        output_model.metadata[metric_name] = metric_value\n\n    labels = {k: str(v).replace(\".\", \"\") for k, v in labels.items()}\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n    aiplatform.Model.upload(\n        display_name = model_name,\n        artifact_uri = input_model.path,\n        serving_container_image_uri=\"gcr.io/anime-rec-dev/user_anime_infer_ranking:latest\",\n        labels = labels\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-10": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-11": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-12": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-13": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-14": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-15": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-16": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-17": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-18": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-19": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-2": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-20": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-3": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-4": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-5": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-6": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-7": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-8": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        },
        "exec-run-query-save-to-bq-table-and-gcs-and-vertexai-9": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "run_query_save_to_bq_table_and_gcs_and_vertexai"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery==2.31.0' 'google-cloud-aiplatform==1.11.0' 'kfp==1.8.10' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef run_query_save_to_bq_table_and_gcs_and_vertexai(\n    query: str,\n    project_id: str, \n    destination_dataset_id: str, \n    destination_table_id: str,\n    gcs_output_format: str,\n    output_data_path: Output[Dataset]\n):\n\n    import logging\n    from google.cloud import bigquery\n    from google.api_core.exceptions import Conflict \n\n    logging.basicConfig(\n        format='%(levelname)s: %(asctime)s: %(message)s',\n        level=logging.INFO\n    )\n\n    client = bigquery.Client(project=project_id)\n\n    try:\n        dataset = bigquery.Dataset(f\"{project_id}.{destination_dataset_id}\")\n        dataset.location = \"us-central1\"\n        dataset = client.create_dataset(dataset, timeout=30)\n        logging.info(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n    except Conflict as e:\n        pass\n\n    destination_table_ref = client.dataset(destination_dataset_id).table(destination_table_id)\n\n    job_config = bigquery.QueryJobConfig()\n    job_config.destination = destination_table_ref\n\n    query_job = client.query(\n        query=query,\n        location='us-central1',\n        job_config=job_config\n    )\n    logging.info(f\"Started running query and saving results to BQ table : {destination_table_ref.path}\")\n\n    query_job.result()\n    logging.info(f\"Finished running query and saved results to BQ table : {destination_table_ref.path}\")\n    logging.info(f\"{destination_table_ref.path} has {client.get_table(destination_table_ref).num_rows} rows\")\n\n    if gcs_output_format == 'csv':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.field_delimiter = ','\n        job_config.destination_format = bigquery.job.DestinationFormat.CSV\n\n    elif gcs_output_format == 'avro':\n        job_config = bigquery.job.ExtractJobConfig()\n        job_config.destination_format = bigquery.job.DestinationFormat.AVRO\n        job_config.use_avro_logical_types = True\n        job_config.compression = bigquery.Compression.SNAPPY\n\n    else:\n        raise(f\"{gcs_output_format} format is not supported. Specify either 'CSV' or 'AVRO'\")\n\n    gcs_output_path = output_data_path.path.replace('/gcs/', 'gs://') + \"/*\"\n    extract_job = client.extract_table(\n        source=destination_table_ref,\n        destination_uris=gcs_output_path,\n        location=\"us-central1\",\n        job_config=job_config\n    )\n    logging.info(f\"Started exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    extract_job.result()\n    logging.info(f\"Finished exporting BQ table {destination_table_ref.path} to {gcs_output_path}\")\n\n    client.close()\n\n    from google.cloud import aiplatform\n    dataset_name = \"_\".join(destination_dataset_id.split(\"_\")[:-1])\n    dataset_name = f\"{dataset_name}_{destination_table_id}\"\n\n    aiplatform.init(\n        project=project_id, \n        location='us-central1',\n        staging_bucket='gs://anime-rec-dev-ml-pipelines'\n    )\n\n    _ = aiplatform.TabularDataset.create(\n        display_name=dataset_name, \n        gcs_source=[gcs_output_path[:-1]]\n    )\n\n"
            ],
            "image": "python:3.7"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "user-anime-recommendation-pipeline"
    },
    "root": {
      "dag": {
        "outputs": {
          "artifacts": {
            "component-3-metrics_path": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "component-3-metrics_path",
                  "producerSubtask": "condition-yes-run-retrieval-1"
                }
              ]
            },
            "component-5-metrics_path": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "component-5-metrics_path",
                  "producerSubtask": "condition-yes-run-retrieval-1"
                }
              ]
            },
            "component-7-metrics_path": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "component-7-metrics_path",
                  "producerSubtask": "condition-no-run-retrieval-4"
                }
              ]
            },
            "component-9-metrics_path": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "component-9-metrics_path",
                  "producerSubtask": "condition-no-run-retrieval-4"
                }
              ]
            },
            "component-metrics_path": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "component-metrics_path",
                  "producerSubtask": "condition-yes-run-retrieval-1"
                }
              ]
            },
            "get-model-training-details-2-output_metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "get-model-training-details-2-output_metrics",
                  "producerSubtask": "condition-yes-run-retrieval-1"
                }
              ]
            },
            "get-model-training-details-3-output_metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "get-model-training-details-3-output_metrics",
                  "producerSubtask": "condition-yes-run-retrieval-1"
                }
              ]
            },
            "get-model-training-details-4-output_metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "get-model-training-details-4-output_metrics",
                  "producerSubtask": "condition-no-run-retrieval-4"
                }
              ]
            },
            "get-model-training-details-5-output_metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "get-model-training-details-5-output_metrics",
                  "producerSubtask": "condition-no-run-retrieval-4"
                }
              ]
            },
            "get-model-training-details-output_metrics": {
              "artifactSelectors": [
                {
                  "outputArtifactKey": "get-model-training-details-output_metrics",
                  "producerSubtask": "condition-yes-run-retrieval-1"
                }
              ]
            }
          }
        },
        "tasks": {
          "condition-no-run-retrieval-4": {
            "componentRef": {
              "name": "comp-condition-no-run-retrieval-4"
            },
            "dependentTasks": [
              "run-query-save-to-bq-table-and-gcs-and-vertexai",
              "run-query-save-to-bq-table-and-gcs-and-vertexai-2"
            ],
            "inputs": {
              "artifacts": {
                "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_data_path",
                    "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-2"
                  }
                },
                "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_data_path",
                    "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai"
                  }
                }
              },
              "parameters": {
                "pipelineparam--data_format": {
                  "componentInputParameter": "data_format"
                },
                "pipelineparam--dataset_id": {
                  "componentInputParameter": "dataset_id"
                },
                "pipelineparam--list_ranking": {
                  "componentInputParameter": "list_ranking"
                },
                "pipelineparam--project_id": {
                  "componentInputParameter": "project_id"
                },
                "pipelineparam--run_retrieval": {
                  "componentInputParameter": "run_retrieval"
                }
              }
            },
            "taskInfo": {
              "name": "condition-no-run-retrieval-4"
            },
            "triggerPolicy": {
              "condition": "inputs.parameters['pipelineparam--run_retrieval'].string_value == 'false'"
            }
          },
          "condition-yes-run-retrieval-1": {
            "componentRef": {
              "name": "comp-condition-yes-run-retrieval-1"
            },
            "dependentTasks": [
              "run-query-save-to-bq-table-and-gcs-and-vertexai",
              "run-query-save-to-bq-table-and-gcs-and-vertexai-2"
            ],
            "inputs": {
              "artifacts": {
                "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-2-output_data_path": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_data_path",
                    "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai-2"
                  }
                },
                "pipelineparam--run-query-save-to-bq-table-and-gcs-and-vertexai-output_data_path": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "output_data_path",
                    "producerTask": "run-query-save-to-bq-table-and-gcs-and-vertexai"
                  }
                }
              },
              "parameters": {
                "pipelineparam--data_format": {
                  "componentInputParameter": "data_format"
                },
                "pipelineparam--dataset_id": {
                  "componentInputParameter": "dataset_id"
                },
                "pipelineparam--list_ranking": {
                  "componentInputParameter": "list_ranking"
                },
                "pipelineparam--project_id": {
                  "componentInputParameter": "project_id"
                },
                "pipelineparam--run_retrieval": {
                  "componentInputParameter": "run_retrieval"
                }
              }
            },
            "taskInfo": {
              "name": "condition-yes-run-retrieval-1"
            },
            "triggerPolicy": {
              "condition": "inputs.parameters['pipelineparam--run_retrieval'].string_value == 'true'"
            }
          },
          "run-query-save-to-bq-table-and-gcs-and-vertexai": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai"
            },
            "inputs": {
              "parameters": {
                "destination_dataset_id": {
                  "componentInputParameter": "dataset_id"
                },
                "destination_table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "list_anime"
                    }
                  }
                },
                "gcs_output_format": {
                  "componentInputParameter": "data_format"
                },
                "project_id": {
                  "componentInputParameter": "project_id"
                },
                "query": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "\n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    "
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "DATA: list anime"
            }
          },
          "run-query-save-to-bq-table-and-gcs-and-vertexai-2": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-run-query-save-to-bq-table-and-gcs-and-vertexai-2"
            },
            "inputs": {
              "parameters": {
                "destination_dataset_id": {
                  "componentInputParameter": "dataset_id"
                },
                "destination_table_id": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "list_user"
                    }
                  }
                },
                "gcs_output_format": {
                  "componentInputParameter": "data_format"
                },
                "project_id": {
                  "componentInputParameter": "project_id"
                },
                "query": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "\n        WITH \n        list_anime AS (\n            \n        SELECT anime_id\n        FROM `anime-rec-dev.processed_area.user_anime`\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY anime_id\n        HAVING COUNT(*) >= 1000\n    \n        ),\n        filtered_user_anime_on_anime AS (\n            \n        SELECT A.*\n        FROM `anime-rec-dev.processed_area.user_anime` A\n        INNER JOIN list_anime B\n        ON A.anime_id = B.anime_id\n    \n        )\n        SELECT user_id\n        FROM filtered_user_anime_on_anime\n        WHERE status = 'completed' AND score IS NOT NULL\n        GROUP BY user_id\n        HAVING COUNT(*) >= 50\n    "
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "DATA: list user"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "data_format": {
            "type": "STRING"
          },
          "dataset_id": {
            "type": "STRING"
          },
          "list_ranking": {
            "type": "STRING"
          },
          "project_id": {
            "type": "STRING"
          },
          "run_retrieval": {
            "type": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "component-3-metrics_path": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "component-5-metrics_path": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "component-7-metrics_path": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "component-9-metrics_path": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "component-metrics_path": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "get-model-training-details-2-output_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "get-model-training-details-3-output_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "get-model-training-details-4-output_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "get-model-training-details-5-output_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "get-model-training-details-output_metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.10"
  },
  "runtimeConfig": {
    "parameters": {
      "data_format": {
        "stringValue": "csv"
      },
      "dataset_id": {
        "stringValue": "ml_pipelines"
      },
      "list_ranking": {
        "stringValue": "false"
      },
      "project_id": {
        "stringValue": "anime-rec-dev"
      },
      "run_retrieval": {
        "stringValue": "false"
      }
    }
  }
}