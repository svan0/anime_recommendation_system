{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae515388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimeMainPicModel(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                unique_anime_ids, \n",
    "                anime_main_pic_url,\n",
    "                img_height = 192, \n",
    "                img_width = 128,\n",
    "                base_model_name = \"efficientnet\",\n",
    "                anime_embedding_size = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.anime_id_lookup_layer = tf.keras.layers.StringLookup(\n",
    "            vocabulary = unique_anime_ids, \n",
    "            num_oov_indices = 0,\n",
    "            name = 'anime_pic_model_id_lookup'\n",
    "        )\n",
    "\n",
    "        anime_img_tf_ds = self.__class__.get_image_dataset(anime_main_pic_url, img_height, img_width)\n",
    "        anime_img_model = self.__class__.get_image_embedding_model(base_model_name, img_height, img_width)\n",
    "\n",
    "        anime_image_embeddings = anime_img_model.predict(anime_img_tf_ds)\n",
    "        num_animes = anime_image_embeddings.shape[0]\n",
    "        img_emb_dim = anime_image_embeddings.shape[1]\n",
    "        self.image_embedding_layer = tf.keras.layers.Embedding(\n",
    "            num_animes,\n",
    "            img_emb_dim,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(anime_image_embeddings),\n",
    "            trainable = False,\n",
    "            name = 'anime_img_base_model_embedding'\n",
    "        )\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(anime_embedding_size, activation = 'relu')\n",
    "    \n",
    "    def call(self, anime_id):\n",
    "        anime_idx = self.anime_id_lookup_layer(anime_id)\n",
    "        anime_image_embedding = self.image_embedding_layer(anime_idx)\n",
    "        anime_embedding = self.final_layer(anime_image_embedding)\n",
    "        return anime_embedding\n",
    "\n",
    "    @staticmethod\n",
    "    def download_image(img_url, img_height = 192, img_width = 128):\n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                with urlopen(img_url) as request:\n",
    "                    img_array = np.asarray(bytearray(request.read()), dtype=np.uint8)\n",
    "                img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_AREA)\n",
    "                return img\n",
    "            except Exception as e:\n",
    "                print(e, img_url)\n",
    "                continue\n",
    "        return np.zeros((img_height, img_width, 3))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_image_dataset(anime_main_pic_df, img_height = 192, img_width = 128):\n",
    "        anime_image_ds = tf.data.Dataset.from_tensor_slices(anime_main_pic_df)\n",
    "        anime_image_ds = anime_image_ds.map(\n",
    "            lambda img_url : tf.py_function(func = lambda x : AnimeMainPicModel.download_image(x.numpy().decode('utf-8'), img_height, img_width), \n",
    "                            inp=[img_url], \n",
    "                            Tout=tf.uint8)\n",
    "        )\n",
    "        anime_image_ds = anime_image_ds.batch(128)\n",
    "        return anime_image_ds\n",
    "\n",
    "    @staticmethod\n",
    "    def get_base_model(base_model_name, img_height = 192, img_width = 128):\n",
    "\n",
    "        if base_model_name.lower() == \"densenet\":\n",
    "            from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
    "            return  preprocess_input,\\\n",
    "                    DenseNet121(weights='imagenet', input_shape = (img_height, img_width, 3), include_top=False, pooling = 'max')\n",
    "\n",
    "        if base_model_name.lower() == \"efficientnet\":\n",
    "            from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "            return  preprocess_input,\\\n",
    "                    EfficientNetB0(weights='imagenet', input_shape = (img_height, img_width, 3), include_top=False, pooling = 'max')\n",
    "\n",
    "        if base_model_name.lower() == \"mobilenet\":\n",
    "            from tensorflow.keras.applications import MobileNetV3Small\n",
    "            from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "            return  preprocess_input,\\\n",
    "                    MobileNetV3Small(weights='imagenet', input_shape = (img_height, img_width, 3), include_top=False, pooling = 'max')\n",
    "        \n",
    "        if base_model_name.lower() == \"nasnet\":\n",
    "            from tensorflow.keras.applications.nasnet import NASNetMobile, preprocess_input\n",
    "            return  preprocess_input,\\\n",
    "                    NASNetMobile(weights='imagenet', input_shape = (img_height, img_width, 3), include_top=False, pooling = 'max')\n",
    "        \n",
    "        if base_model_name.lower() == \"resnet\":\n",
    "            from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "            return  preprocess_input,\\\n",
    "                    ResNet50V2(weights='imagenet', input_shape = (img_height, img_width, 3), include_top=False, pooling = 'max')\n",
    "        \n",
    "        from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "        return  preprocess_input,\\\n",
    "                ResNet50V2(weights='imagenet', input_shape = (img_height, img_width, 3), include_top=False, pooling = 'max')\n",
    "\n",
    "    @staticmethod\n",
    "    def get_image_embedding_model(base_model_name, img_height = 192, img_width = 128):\n",
    "        preprocessing_function, base_model = AnimeMainPicModel.get_base_model(base_model_name, img_height, img_width)\n",
    "        raw_image = tf.keras.layers.Input(shape=(img_height, img_width, 3), dtype = tf.uint8, name = 'raw_image')\n",
    "        preprocessed_image = tf.cast(raw_image, dtype = tf.float32)\n",
    "        preprocessed_image = preprocessing_function(preprocessed_image)\n",
    "        image_embedding = base_model(preprocessed_image)\n",
    "        return tf.keras.Model(raw_image, image_embedding)\n",
    "\n",
    "class AnimeTextModel(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                unique_anime_ids, \n",
    "                anime_text_feature,\n",
    "                base_model_name = \"bert\",\n",
    "                anime_embedding_size = 32):\n",
    "\n",
    "        super().__init__()\n",
    "        self.anime_id_lookup_layer = tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_anime_ids, \n",
    "            num_oov_indices=0,\n",
    "            name = 'anime_text_model_id_lookup'\n",
    "        )\n",
    "        text_tf_ds = tf.data.Dataset.from_tensor_slices(anime_text_feature).batch(128)\n",
    "        text_embedding_model = self.__class__.get_text_embedding_model(base_model_name)\n",
    "\n",
    "        anime_text_embeddings = text_embedding_model.predict(text_tf_ds)\n",
    "\n",
    "        num_animes = anime_text_embeddings.shape[0]\n",
    "        text_emb_dim = anime_text_embeddings.shape[1]\n",
    "\n",
    "        self.text_embedding_layer = tf.keras.layers.Embedding(\n",
    "            num_animes,\n",
    "            text_emb_dim,\n",
    "            embeddings_initializer=tf.keras.initializers.Constant(anime_text_embeddings),\n",
    "            trainable=False,\n",
    "            name = 'text_embedding_layer'\n",
    "        )\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(anime_embedding_size, activation = 'relu')\n",
    "\n",
    "    def call(self, anime_id):\n",
    "        anime_idx = self.anime_id_lookup_layer(anime_id)\n",
    "        anime_text_embedding = self.text_embedding_layer(anime_idx)\n",
    "        anime_embedding = self.final_layer(anime_text_embedding)\n",
    "        return anime_embedding\n",
    "\n",
    "    @staticmethod\n",
    "    def get_base_model(base_model_name):\n",
    "        if base_model_name.lower() == \"bert\":\n",
    "            preprocess_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "            model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\", \n",
    "                                    trainable=False)\n",
    "            return preprocess_model, model\n",
    "        \n",
    "        preprocess_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "        model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\", \n",
    "                                    trainable=False)\n",
    "        return preprocess_model, model\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_text_embedding_model(base_model_name):\n",
    "        preprocessing_function, base_model = AnimeTextModel.get_base_model(base_model_name)\n",
    "        text = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'text')\n",
    "        preprocessed_text = preprocessing_function(text)\n",
    "        text_embedding = base_model(preprocessed_text)\n",
    "        text_embedding = text_embedding[\"pooled_output\"]\n",
    "        return tf.keras.Model(text, text_embedding)\n",
    "\n",
    "class AnimeOneHotModel(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                unique_anime_ids,\n",
    "                one_hot_feature,\n",
    "                vocabulary):\n",
    "        super().__init__()\n",
    "\n",
    "        self.anime_id_lookup_layer = tf.keras.layers.StringLookup(\n",
    "            vocabulary = unique_anime_ids, \n",
    "            num_oov_indices = 0,\n",
    "            name = 'anime_onehot_model_id_lookup'\n",
    "        )\n",
    "\n",
    "        one_hot_feature_ds = tf.data.Dataset.from_tensor_slices(one_hot_feature).batch(128)\n",
    "        one_hot_layer = tf.keras.layers.StringLookup(vocabulary = vocabulary,\n",
    "                                                    output_mode = \"one_hot\",\n",
    "                                                    num_oov_indices = 0\n",
    "                                                    )\n",
    "        one_hot_encodings = one_hot_layer(one_hot_feature_ds)\n",
    "        \n",
    "        num_animes = one_hot_encodings.shape[0]\n",
    "        num_one_hot_dims = one_hot_encodings.shape[1]\n",
    "\n",
    "        self.one_hot_encoding_layer = tf.keras.layers.Embedding(\n",
    "            num_animes,\n",
    "            num_one_hot_dims,\n",
    "            embeddings_initializer = tf.keras.initializers.Constant(one_hot_encodings),\n",
    "            trainable = False,\n",
    "            name = 'one_hot_enconding_layer'\n",
    "        )\n",
    "    \n",
    "    def call(self, anime_id):\n",
    "        anime_idx = self.anime_id_lookup_layer(anime_id)\n",
    "        anime_onehot_encoding = self.one_hot_encoding_layer(anime_idx)\n",
    "        return anime_onehot_encoding\n",
    "\n",
    "class AnimeMultiHotModel(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                unique_anime_ids,\n",
    "                multi_hot_feature,\n",
    "                vocabulary):\n",
    "        super().__init__()\n",
    "\n",
    "        self.anime_id_lookup_layer = tf.keras.layers.StringLookup(\n",
    "            vocabulary = unique_anime_ids, \n",
    "            num_oov_indices = 0,\n",
    "            name = 'anime_multihot_model_id_lookup'\n",
    "        )\n",
    "\n",
    "        multi_hot_feature = multi_hot_feature.apply(lambda x : self.__class__.multi_hot_same_shape(x, max_len=len(vocabulary)))\n",
    "        multi_hot_feature = list(multi_hot_feature)\n",
    "\n",
    "        multi_hot_layer = tf.keras.layers.StringLookup(vocabulary = vocabulary,\n",
    "                                                    output_mode = \"multi_hot\",\n",
    "                                                    num_oov_indices=1\n",
    "                                                    )\n",
    "        multi_hot_encodings = multi_hot_layer(multi_hot_feature)\n",
    "        multi_hot_encodings = multi_hot_encodings[:, 1:]\n",
    "        \n",
    "        num_animes = multi_hot_encodings.shape[0]\n",
    "        num_multi_hot_dims = multi_hot_encodings.shape[1]\n",
    "\n",
    "        self.multi_hot_encoding_layer = tf.keras.layers.Embedding(\n",
    "            num_animes,\n",
    "            num_multi_hot_dims,\n",
    "            embeddings_initializer=tf.keras.initializers.Constant(multi_hot_encodings),\n",
    "            trainable = False,\n",
    "            name = 'multi_hot_enconding_layer'\n",
    "        )\n",
    "    \n",
    "    def call(self, anime_id):\n",
    "        anime_idx = self.anime_id_lookup_layer(anime_id)\n",
    "        anime_multihot_encoding = self.multi_hot_encoding_layer(anime_idx)\n",
    "        return anime_multihot_encoding\n",
    "    \n",
    "    @staticmethod\n",
    "    def multi_hot_same_shape(list_entities, max_len = 30):\n",
    "        list_entities = list_entities[:max_len]\n",
    "        num_add = max_len - list_entities.shape[0]\n",
    "        return np.concatenate([list_entities , num_add * [\"[UNK]\"]])\n",
    "\n",
    "class CombinedAnimeModel(tf.keras.Model):\n",
    "    def __init__(self, sub_models = [], anime_embedding_size = 32):\n",
    "        super().__init__()\n",
    "\n",
    "        assert(len(sub_models) > 1)\n",
    "        self.sub_models = sub_models\n",
    "        self.final_layer = tf.keras.layers.Dense(anime_embedding_size, activation = 'relu', name = 'combined_anime_final_layer')\n",
    "    \n",
    "    def call(self, anime_id):\n",
    "        sub_embeddings = [\n",
    "            sub_model(anime_id) \n",
    "            for sub_model in self.sub_models\n",
    "        ]\n",
    "        concat_embedding = tf.concat(sub_embeddings, axis=-1)\n",
    "        anime_embedding = self.final_layer(concat_embedding)\n",
    "        return anime_embedding\n",
    "\n",
    "###########################\n",
    "\n",
    "class CombinedUserModel(tf.keras.Model):\n",
    "    def __init__(self, sub_models = [], user_embedding_size = 32):\n",
    "        super().__init__()\n",
    "\n",
    "        assert(len(sub_models) > 1)\n",
    "        self.sub_models = sub_models\n",
    "        self.final_layer = tf.keras.layers.Dense(user_embedding_size, activation = 'relu', name = 'combined_user_final_layer')\n",
    "    \n",
    "    def call(self, user_id):\n",
    "        sub_embeddings = [\n",
    "            sub_model(user_id) \n",
    "            for sub_model in self.sub_models\n",
    "        ]\n",
    "        concat_embedding = tf.concat(sub_embeddings, axis=-1)\n",
    "        user_embedding = self.final_layer(concat_embedding)\n",
    "        return user_embedding\n",
    "##############################\n",
    "    \n",
    "class RandomUserAnimeListRankingModel(BaseUserAnimeListRankingModel):\n",
    "    def __init__(self, topn = 5, positive_threshold = 8.0):\n",
    "        super().__init__(topn, positive_threshold)\n",
    "\n",
    "    def call(self, features):\n",
    "        anime_id = features['anime_id']\n",
    "        pred_ratings = tf.random.uniform(tf.shape(anime_id), minval = 1.0, maxval = 10.0)\n",
    "        return pred_ratings\n",
    "\n",
    "class PerfectUserAnimeListRankingModel(BaseUserAnimeListRankingModel):\n",
    "    def __init__(self, topn = 5, positive_threshold = 8.0):\n",
    "        super().__init__(topn, positive_threshold)\n",
    "          \n",
    "    def call(self, features):\n",
    "        pred_ratings = features['score']\n",
    "        return pred_ratings\n",
    "\n",
    "class AverageUserAnimeRatingListRankingModel(BaseUserAnimeListRankingModel):\n",
    "    def __init__(self, anime_ids, anime_scores, topn = 5, positive_threshold = 8.0):\n",
    "        super().__init__(topn, positive_threshold)\n",
    "        self.ratings = tf.lookup.StaticHashTable(\n",
    "                tf.lookup.KeyValueTensorInitializer(anime_ids, anime_scores),\n",
    "                default_value=-1\n",
    "        )\n",
    "    def call(self, features):\n",
    "        anime_id = features['anime_id']\n",
    "        pred_ratings = self.ratings.lookup(anime_id)\n",
    "        return pred_ratings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anime_rec_sys] *",
   "language": "python",
   "name": "conda-env-anime_rec_sys-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
